#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
@author: Ivan Hernandez

Netcdf files are created with the same structure as the hydrodynamic data files.

Same dimensions: lon, lat, z and time.
Same variables: lon, lat, z, time, u, v.

The distance data is added to the u variable only.
The v variable has 0 values.

Netcdf files must be deleted if this process is to be repeated, files cannot be replaced.

The files are created for same datetime in the config.
"""
import netCDF4 as nc
import numpy as np
import pandas as pd
import datetime as dt
from datetime import date
from datetime import timedelta
from netCDF4 import date2num,num2date
import os

# import file from another folder
import sys
sys.path.append('../')
from config import sample_data as cfg


# creates folder for pickles if it does not exist
path_nodes = '../hydrodynamic_data/nodes/'
os.makedirs(path_nodes, exist_ok=True)

# Simulation init and end times
sim_split_i = cfg.sim_init.split("/")
sim_split_e = cfg.sim_end.split("/")

# simulation init date to a list
YYi = [int(sim_split_i[0]),int(sim_split_i[1]),int(sim_split_i[2])]
YYe = [int(sim_split_e[0]),int(sim_split_e[1]),int(sim_split_e[2])]


# create date list. These dates correspond to the simulation
# the files produced do work on other dates, however
d0 = date(YYi[0], YYi[1], YYi[2])
d1 = date(YYe[0], YYe[1], YYe[2])
delta = d1 - d0

# calculates nuber of hours for the date list
num_days = delta.days + 1
num_hours = num_days * 24
base_time = dt.datetime(YYi[0], YYi[1], YYi[2], 0)
date_list_dt = [base_time + dt.timedelta(hours=x) for x in range(num_hours)]


# read the pickle files
df_h = pd.read_pickle('../pickles/nodes/to_netcdf/harbour_nodes.pkl')
df_c = pd.read_pickle('../pickles/nodes/to_netcdf/coastal_nodes.pkl')
df_r = pd.read_pickle('../pickles/nodes/to_netcdf/regional_nodes.pkl')

# convert to numpy arrays
lat_h = df_h['latitude'].to_numpy()
lon_h = df_h['longitude'].to_numpy()

lat_c = df_c['latitude'].to_numpy()
lon_c = df_c['longitude'].to_numpy()

lat_r = df_r['latitude'].to_numpy()
lon_r = df_r['longitude'].to_numpy()

# groups and converts to a series then to a list
# node distance data is added to the u variable list
u_h = df_h.groupby('latitude')['distance_shore'].apply(pd.Series.tolist).tolist()
u_c = df_c.groupby('latitude')['distance_shore'].apply(pd.Series.tolist).tolist()
u_r = df_r.groupby('latitude')['distance_shore'].apply(pd.Series.tolist).tolist()

# creates a list in the same shape for the v variable list, but the values are full of zeros
v_h = np.zeros_like(u_h)
v_c = np.zeros_like(u_c)
v_r = np.zeros_like(u_r)

# inserts the list generated by the grouped series into another list
# this is to satisfy the shape requirement of the data to go into the nc file
u_h_i = []
u_h_i.insert(0, u_h)
v_h_i = []
v_h_i.insert(0, v_h)

u_c_i = []
u_c_i.insert(0, u_c)
v_c_i = []
v_c_i.insert(0, v_c)

u_r_i = []
u_r_i.insert(0, u_r)
v_r_i = []
v_r_i.insert(0, v_r)

# convert this final list to a numpy array
u_h_arr = np.array(u_h_i)
v_h_arr = np.array(v_h_i)

u_c_arr = np.array(u_c_i)
v_c_arr = np.array(v_c_i)

u_r_arr = np.array(u_r_i)
v_r_arr = np.array(v_r_i)


# removes duplicates from list to create the lat and lon lists along the dimensions
lat_list_h = list(dict.fromkeys(lat_h))
lon_list_h = list(dict.fromkeys(lon_h))

lat_list_c = list(dict.fromkeys(lat_c))
lon_list_c = list(dict.fromkeys(lon_c))

lat_list_r = list(dict.fromkeys(lat_r))
lon_list_r = list(dict.fromkeys(lon_r))

# the depth dimension value is 0, since these would be only for the surface 
depth_list_h = [0]
depth_list_c = [0]
depth_list_r = [0]

# specify path for netcdf diles
ncfile_h = nc.Dataset(path_nodes + 'harbour_nodes.nc', mode='w', format='NETCDF4')
ncfile_c = nc.Dataset(path_nodes + 'coastal_nodes.nc', mode='w', format='NETCDF4')
ncfile_r = nc.Dataset(path_nodes + 'regional_nodes.nc', mode='w', format='NETCDF4')

# create dimensions
lat_dim_h = ncfile_h.createDimension('latitude', len(lat_list_h)) # latitude axis
lon_dim_h = ncfile_h.createDimension('longitude', len(lon_list_h)) # longitude axis
depth_dim_h = ncfile_h.createDimension('depth', len(depth_list_h)) # depth axis
time_dim_h = ncfile_h.createDimension('time', None) # time axis

lat_dim_c = ncfile_c.createDimension('latitude', len(lat_list_c)) # latitude axis
lon_dim_c = ncfile_c.createDimension('longitude', len(lon_list_c)) # longitude axis
depth_dim_c = ncfile_c.createDimension('depth', len(depth_list_c)) # depth axis
time_dim_c = ncfile_c.createDimension('time', None) # time axis

lat_dim_r = ncfile_r.createDimension('latitude', len(lat_list_r)) # latitude axis
lon_dim_r = ncfile_r.createDimension('longitude', len(lon_list_r)) # longitude axis
depth_dim_r = ncfile_r.createDimension('depth', len(depth_list_r)) # depth axis
time_dim_r =  ncfile_r.createDimension('time', None) # time axis

# create harbour variables with their attributes
lon_h = ncfile_h.createVariable('longitude', np.float32, ('longitude',), fill_value='nan')
lat_h = ncfile_h.createVariable('latitude', np.float32, ('latitude',), fill_value='nan')
depth_h = ncfile_h.createVariable('depth', np.float64, ('depth',), fill_value='nan')
time_h = ncfile_h.createVariable('time', np.float64, ('time',), fill_value='nan')
u_h = ncfile_h.createVariable('u', np.float64, ('time','depth','latitude','longitude',), fill_value='-32767')
v_h = ncfile_h.createVariable('v', np.float64, ('time','depth','latitude','longitude'), fill_value='-32767')

lon_h.standard_name = 'longitude'
lon_h.long_name = 'Longitude'
lon_h.units = 'degrees_east'
lon_h.axis = 'X'

lat_h.standard_name = 'latitude'
lat_h.long_name = 'Latitude'
lat_h.units = 'degrees_north'
lat_h.axis = 'Y'

depth_h.standard_name = 'depth'
depth_h.long_name = 'Depth'
depth_h.units = 'm'
depth_h.positive = 'down'
depth_h.axis = 'Z'

u_h.standard_name = 'eastward_sea_water_velocity' 
u_h.long_name = 'Eastward velocity' 
u_h.units = 'm s-1'
u_h.unit_long = 'Meters per second'
u_h.add_offset = 0.0
u_h.scale_factor = 1e-04
u_h.missing_value = -32767

v_h.standard_name = 'northward_sea_water_velocity'
v_h.long_name = 'Northward velocity'
v_h.units = 'm s-1'
v_h.unit_long = 'Meters per second'
v_h.add_offset = 0.0
v_h.scale_factor = 1e-04
v_h.missing_value = -32767

time_h.standard_name = 'time'
time_h.long_name = 'time'
time_h.units = 'hours since 1950-01-01'
time_h.axis = 'T'
time_h.calendar = 'standard'

# create coastal variables with their attributes
lon_c = ncfile_c.createVariable('longitude', np.float32, ('longitude',), fill_value='nan')
lat_c = ncfile_c.createVariable('latitude', np.float32, ('latitude',), fill_value='nan')
depth_c = ncfile_c.createVariable('depth', np.float64, ('depth',), fill_value='nan')
time_c = ncfile_c.createVariable('time', np.float64, ('time',), fill_value='nan')
u_c = ncfile_c.createVariable('u', np.float64, ('time','depth','latitude','longitude',), fill_value='-32767')
v_c = ncfile_c.createVariable('v', np.float64, ('time','depth','latitude','longitude'), fill_value='-32767')

lon_c.standard_name = 'longitude'
lon_c.long_name = 'Longitude'
lon_c.units = 'degrees_east'
lon_c.axis = 'X'

lat_c.standard_name = 'latitude'
lat_c.long_name = 'Latitude'
lat_c.units = 'degrees_north'
lat_c.axis = 'Y'

depth_c.standard_name = 'depth'
depth_c.long_name = 'Depth'
depth_c.units = 'm' 
depth_c.positive = 'down'
depth_c.axis = 'Z'

u_c.standard_name = 'eastward_sea_water_velocity' 
u_c.long_name = 'Eastward velocity'
u_c.units = 'm s-1'
u_c.unit_long = 'Meters per second'
u_c.add_offset = 0.0
u_c.scale_factor = 1e-04
u_c.missing_value = -32767

v_c.standard_name = 'northward_sea_water_velocity'
v_c.long_name = 'Northward velocity'
v_c.units = 'm s-1'
v_c.unit_long = 'Meters per second'
v_c.add_offset = 0.0
v_c.scale_factor = 1e-04
v_c.missing_value = -32767

time_c.standard_name = 'time'
time_c.long_name = 'time'
time_c.units = 'hours since 1950-01-01'
time_c.axis = 'T'
time_c.calendar = 'standard'

# create regional variables with their attributes
lon_r = ncfile_r.createVariable('longitude', np.float32, ('longitude',), fill_value='nan')
lat_r = ncfile_r.createVariable('latitude', np.float32, ('latitude',), fill_value='nan')
depth_r = ncfile_r.createVariable('depth', np.float64, ('depth',), fill_value='nan')
time_r = ncfile_r.createVariable('time', np.float64, ('time',), fill_value='nan')
u_r = ncfile_r.createVariable('u', np.float64, ('time','depth','latitude','longitude',),fill_value='-32767')
v_r = ncfile_r.createVariable('v', np.float64, ('time','depth','latitude','longitude'), fill_value='-32767')

lon_r.standard_name = 'longitude'
lon_r.long_name = 'Longitude'
lon_r.units = 'degrees_east'
lon_r.axis = 'X'

lat_r.standard_name = 'latitude'
lat_r.long_name = 'Latitude'
lat_r.units = 'degrees_north'
lat_r.axis = 'Y'

depth_r.standard_name = 'depth'
depth_r.long_name = 'Depth'
depth_r.units = 'm' 
depth_r.positive = 'down'
depth_r.axis = 'Z'

u_r.standard_name = 'eastward_sea_water_velocity' 
u_r.long_name = 'Eastward velocity' 
u_r.units = 'm s-1'
u_r.unit_long = 'Meters per second'
u_r.add_offset = 0.0
u_r.scale_factor = 1e-04  # equivalent to scale of 1
u_r.missing_value = -32767

v_r.standard_name = 'northward_sea_water_velocity'
v_r.long_name = 'Northward velocity'
v_r.units = 'm s-1'
v_r.unit_long = 'Meters per second'
v_r.add_offset = 0.0
v_r.scale_factor = 1e-04 # equivalent to scale of 1
v_r.missing_value = -32767

time_r.standard_name = 'time'
time_r.long_name = 'time'
time_r.units = 'hours since 1950-01-01'
time_r.axis = 'T'
time_r.calendar = 'standard'

# create global attributes
ncfile_h.title='Harbour nodes data'
ncfile_c.title='Coastal nodes data'
ncfile_r.title='Regional nodes data'

ncfile_h.feature_type='Node distance to shore'
ncfile_c.feature_type='Node distance to shore'
ncfile_r.feature_type='Node distance to shore'

ncfile_h.Conventions='CF-1.6/CF-1.7'
ncfile_c.Conventions='CF-1.6/CF-1.7'
ncfile_r.Conventions='CF-1.6/CF-1.7'

ncfile_h.institution='Universitat Polit√®cnica de Catalunya'
ncfile_c.institution='Universitat Polit√®cnica de Catalunya'
ncfile_r.institution='Universitat Polit√®cnica de Catalunya'

ncfile_h.source='UPC'
ncfile_c.source='UPC'
ncfile_r.source='UPC'

# prepare the time lists (identical)
date_list_h = date2num(date_list_dt, time_h.units)
date_list_c = date2num(date_list_dt, time_c.units)
date_list_r = date2num(date_list_dt, time_r.units)


# repeat the distance numpy arrays for every time step, otherwise the shape is correct but there is only one instance, creating errors
u_h_arr_t = []
u_h_arr_t.insert(0, u_h_arr)
u_h_arr_t = np.array(u_h_arr_t)
u_h_arr_repeat = np.repeat(u_h_arr_t, len(date_list_h), 0)

u_c_arr_t = []
u_c_arr_t.insert(0, u_c_arr)
u_c_arr_t = np.array(u_c_arr_t)
u_c_arr_repeat = np.repeat(u_c_arr_t, len(date_list_c), 0)

u_r_arr_t = []
u_r_arr_t.insert(0, u_r_arr)
u_r_arr_t = np.array(u_r_arr_t)
u_r_arr_repeat = np.repeat(u_r_arr_t, len(date_list_r), 0)


v_h_arr_t = []
v_h_arr_t.insert(0, v_h_arr)
v_h_arr_t = np.array(v_h_arr_t)
v_h_arr_repeat = np.repeat(v_h_arr_t, len(date_list_h), 0)

v_c_arr_t = []
v_c_arr_t.insert(0, v_c_arr)
v_c_arr_t = np.array(v_c_arr_t)
v_c_arr_repeat = np.repeat(v_c_arr_t, len(date_list_c), 0)

v_r_arr_t = []
v_r_arr_t.insert(0, v_r_arr)
v_r_arr_t = np.array(v_r_arr_t)
v_r_arr_repeat = np.repeat(v_r_arr_t, len(date_list_r), 0)


# populate the variables
lat_h[:] = lat_list_h
lon_h[:] = lon_list_h
depth_h[:] = depth_list_h
time_h[:] = date_list_h
u_h[:,:,:,:] = u_h_arr_repeat # Appends data along unlimited dimension (leftmost, if using time)
v_h[:,:,:,:] = v_h_arr_repeat

lat_c[:] = lat_list_c
lon_c[:] = lon_list_c
depth_c[:] = depth_list_c
time_c[:] = date_list_c
u_c[:,:,:,:] = u_c_arr_repeat
v_c[:,:,:,:] = v_c_arr_repeat 

lat_r[:] = lat_list_r
lon_r[:] = lon_list_r
depth_r[:] = depth_list_r
time_r[:] = date_list_r
u_r[:,:,:,:] = u_r_arr_repeat
v_r[:,:,:,:] = v_r_arr_repeat 


# close the Dataset
ncfile_h.close()
ncfile_c.close()
ncfile_r.close()


print('Datasets are closed!')
